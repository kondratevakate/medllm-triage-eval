{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOG6jImX9yT/Nz3GH4WC9va",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kondratevakate/medllm-triage-eval/blob/main/BioBert_BGEm3_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup and Imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "df = pd.read_csv('random_stratified_test.csv')\n",
        "\n",
        "# 3.1 Define rawâ†’friendly mapping and rename\n",
        "col_map = {\n",
        "    'age':                  'Age'\n",
        "}\n",
        "df = df.rename(columns=col_map)\n",
        "\n",
        "# 3. Preprocess Dataset\n",
        "# Identify vital sign columns (already human-friendly)\n",
        "vital_cols = [\n",
        "    'Temperature', 'HeartRate', 'RespiratoryRate',\n",
        "    'Oxygen', 'SystolicBP', 'DiastolicBP'\n",
        "]\n",
        "# Demographics and target (renamed)\n",
        "other_cols = ['Sex', 'Age', 'ESI']\n",
        "cc_cols    = [c for c in df.columns if c.startswith('cc_')]\n",
        "\n",
        "# Validate presence\n",
        "missing = set(vital_cols + cc_cols + other_cols) - set(df.columns)\n",
        "if missing:\n",
        "    raise KeyError(f\"Missing columns: {missing}\")\n",
        "\n",
        "df = df[vital_cols + cc_cols + other_cols]\n",
        "\n",
        "# 3.4 Clean target\n",
        "df = df.dropna(subset=['ESI']).reset_index(drop=True)\n",
        "df['ESI'] = df['ESI'].astype(int)\n",
        "\n",
        "# %%\n",
        "# 4. Build ComplaintText and embed via BioBERT\n",
        "# Create readable complaint string\n",
        "def complaint_text(row):\n",
        "    names = [col.replace('cc_', '').replace('_', ' ').title()\n",
        "             for col in cc_cols if row[col] == 1]\n",
        "    return ' '.join(names) if names else 'NoComplaint'\n",
        "\n",
        "df['ComplaintText'] = df.apply(complaint_text, axis=1)\n",
        "\n",
        "# 5. Serialize cases (CC as single variable)\n",
        "vital_names = ['Temperature','HeartRate','RespiratoryRate','Oxygen','SystolicBP','DiastolicBP']\n",
        "demo_names = ['Age','Sex']\n",
        "\n",
        "def serialize_row(row):\n",
        "    parts = [f\"{col}: {row[col] if pd.notnull(row[col]) else 'Missing'}\"\n",
        "             for col in vital_names]\n",
        "    parts.append(f\"ChiefComplaint: {row['ComplaintText']}\")\n",
        "    parts += [f\"{col}: {row[col]}\" for col in demo_names]\n",
        "    return '; '.join(parts)\n",
        "\n",
        "df['Serialized'] = df.apply(serialize_row, axis=1)\n"
      ],
      "metadata": {
        "id": "43C6wejt-uBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/BAAI/bge-m3 ./bge-m3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPChzg98HgnG",
        "outputId": "caee722c-bcdd-49cc-f0db-ff83f255d604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into './bge-m3'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 150 (delta 64), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Receiving objects: 100% (150/150), 3.22 MiB | 4.83 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "Filtering content: 100% (9/9), 4.27 GiB | 167.54 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig\n",
        "from torch.cuda.amp import autocast\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "\n",
        "def load_and_preprocess(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    col_map = {\n",
        "        'triage_vital_temp': 'Temperature',\n",
        "        'triage_vital_hr':   'HeartRate',\n",
        "        'triage_vital_rr':   'RespiratoryRate',\n",
        "        'triage_vital_o2':   'Oxygen',\n",
        "        'triage_vital_sbp':  'SystolicBP',\n",
        "        'triage_vital_dbp':  'DiastolicBP',\n",
        "        'gender':            'Sex',\n",
        "        'race':              'Race',\n",
        "        'age':               'Age'\n",
        "    }\n",
        "    df.rename(columns=col_map, inplace=True)\n",
        "\n",
        "    vital_cols = ['Temperature','HeartRate','RespiratoryRate','Oxygen','SystolicBP','DiastolicBP']\n",
        "    cc_cols    = [c for c in df.columns if c.startswith('cc_')]\n",
        "    other_cols = ['Sex','Age','ESI']\n",
        "    df = df[vital_cols + cc_cols + other_cols].dropna(subset=['ESI']).reset_index(drop=True)\n",
        "    df['ESI'] = df['ESI'].astype(int)\n",
        "\n",
        "    df['ComplaintText'] = df.apply(\n",
        "        lambda r: ' '.join(\n",
        "            c.replace('cc_','').replace('_',' ').title()\n",
        "            for c in cc_cols if r[c]==1\n",
        "        ) or \"NoComplaint\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    def serialize(r):\n",
        "        parts = [f\"{c}: {r[c]}\" for c in vital_cols]\n",
        "        parts.append(f\"ChiefComplaint: {r['ComplaintText']}\")\n",
        "        parts += [f\"{c}: {r[c]}\" for c in ['Age','Sex']]\n",
        "        return '; '.join(parts)\n",
        "\n",
        "    df['Serialized'] = df.apply(serialize, axis=1)\n",
        "    return df\n",
        "\n",
        "def get_bge_model(token: str = None):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    quant = BitsAndBytesConfig(load_in_8bit=True)\n",
        "    kwargs = {'trust_remote_code': True, 'quantization_config': quant, 'device_map': 'auto'}\n",
        "    if token:\n",
        "        kwargs['use_auth_token'] = token\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"./bge-m3\", **kwargs)\n",
        "    model     = AutoModel.from_pretrained(\"./bge-m3\", **kwargs).eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "def get_bge_model(token: str = None):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    quant = BitsAndBytesConfig(load_in_8bit=True)\n",
        "    kwargs = {'trust_remote_code': True, 'quantization_config': quant, 'device_map': 'auto'}\n",
        "    if token:\n",
        "        kwargs['use_auth_token'] = token\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"./bge-m3\", **kwargs)\n",
        "    model     = AutoModel.from_pretrained(\"./bge-m3\", **kwargs).eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "def embed_serialized(df: pd.DataFrame, tokenizer, model, bs: int = 64, max_len: int = 64) -> pd.DataFrame:\n",
        "    device = model.device\n",
        "    embs = []\n",
        "    texts = df['Serialized'].tolist()\n",
        "    for i in range(0, len(texts), bs):\n",
        "        batch = texts[i:i+bs]\n",
        "        enc = tokenizer(batch,\n",
        "                        padding='longest',\n",
        "                        truncation=True,\n",
        "                        max_length=max_len,\n",
        "                        return_tensors='pt')\n",
        "        enc = {k:v.to(device) for k,v in enc.items()}\n",
        "        with torch.no_grad(), autocast():\n",
        "            out = model(**enc).last_hidden_state\n",
        "            embs.append(out.mean(dim=1).cpu().numpy())\n",
        "    df['TextEmb'] = list(np.vstack(embs))\n",
        "    return df\n",
        "\n",
        "def train_and_evaluate(df: pd.DataFrame):\n",
        "    X = np.vstack(df['TextEmb'].values)\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "    y = df['ESI'].values\n",
        "\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(512,256),\n",
        "                        early_stopping=True, max_iter=100,\n",
        "                        random_state=42)\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    y_pred = cross_val_predict(mlp, X, y, cv=cv)\n",
        "\n",
        "    return y, y_pred\n",
        "\n",
        "\n",
        "# Execute\n",
        "df = load_and_preprocess('random_stratified_test.csv')\n",
        "tokenizer, model = get_bge_model(token=os.getenv(\"HF_TOKEN\"))\n",
        "df = embed_serialized(df, tokenizer, model)\n",
        "y, y_pred = train_and_evaluate(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrZremsfGkia",
        "outputId": "78918c5a-1941-45db-a510-d3ef2a4a03b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-19429beb47db>:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_row = compute_metrics_row(pd.Series(np.array(y)), pd.Series(y_pred))\n",
        "df_metrics = pd.DataFrame([metrics_row], index=['ExampleModel'])\n",
        "\n",
        "df_metrics.round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "sF3lUR3TFDxX",
        "outputId": "b84aefa4-da61-4486-87de-cc4a00db9931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Acc.     P     R    F1   HR  Mod. F1    NP   OT   UT   ER\n",
              "ExampleModel   0.6  0.58  0.45  0.48  0.6     0.63  0.71  0.2  0.2  0.4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8eec0450-9876-4348-b5fd-4c14b28ae800\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acc.</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F1</th>\n",
              "      <th>HR</th>\n",
              "      <th>Mod. F1</th>\n",
              "      <th>NP</th>\n",
              "      <th>OT</th>\n",
              "      <th>UT</th>\n",
              "      <th>ER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExampleModel</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8eec0450-9876-4348-b5fd-4c14b28ae800')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8eec0450-9876-4348-b5fd-4c14b28ae800 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8eec0450-9876-4348-b5fd-4c14b28ae800');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_metrics\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Acc.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6,\n        \"max\": 0.6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"P\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.58,\n        \"max\": 0.58,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.45,\n        \"max\": 0.45,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.48,\n        \"max\": 0.48,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6,\n        \"max\": 0.6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mod. F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.63,\n        \"max\": 0.63,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.71,\n        \"max\": 0.71,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.71\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.2,\n        \"max\": 0.2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.2,\n        \"max\": 0.2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ER\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.4,\n        \"max\": 0.4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "# 1) Select device dynamically\n",
        "device = torch.device(\"cuda\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 1) Load & prepare BioBERT on GPU + FP16\n",
        "\n",
        "model = AutoModel.from_pretrained('dmis-lab/biobert-base-cased-v1.2')\n",
        "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2')\n",
        "model.to(device).eval()\n",
        "model.half()   # switch weights to FP16\n",
        "\n",
        "def embed_texts_fast(texts, batch_size=64, max_length=64):\n",
        "    embs = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i : i + batch_size]\n",
        "        # 2) tokenize on CPU, then move to GPU\n",
        "        enc = tokenizer(\n",
        "            batch,\n",
        "            padding='longest',\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        enc = {k: v.to('cuda', non_blocking=True) for k, v in enc.items()}\n",
        "\n",
        "        # 3) run in mixed precision\n",
        "        with torch.no_grad(), autocast():\n",
        "            out = model(**enc).last_hidden_state  # [B, L, D]\n",
        "\n",
        "        # 4) mean-pool in FP16 then move to CPU float32\n",
        "        emb = out.mean(dim=1).cpu().float().numpy()  # [B, D]\n",
        "        embs.append(emb)\n",
        "\n",
        "    return np.vstack(embs)\n",
        "\n",
        "# # 5) Compute your embeddings\n",
        "# df['TextEmb'] = list(embed_texts_fast(df['Serialized'].tolist(), batch_size=64, max_length=64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzhSmN3x6Uii",
        "outputId": "85e42bf6-3e7a-4945-c1e6-e67915027263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics_row(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute triage performance metrics for a single model/run.\n",
        "\n",
        "    Returns a dict with keys:\n",
        "      'Acc.', 'P', 'R', 'F1', 'HR', 'Mod. F1', 'NP', 'OT', 'UT', 'ER'\n",
        "    \"\"\"\n",
        "    # Overall\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    p   = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    r   = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1  = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    # High-risk recall (ESI 1&2)\n",
        "    high_true = y_true.isin([1,2]).astype(int)\n",
        "    high_pred = pd.Series(y_pred).isin([1,2]).astype(int)\n",
        "    hr = recall_score(high_true, high_pred, zero_division=0)\n",
        "\n",
        "    # Moderate (ESI-3) F1\n",
        "    mod_true = (y_true == 3).astype(int)\n",
        "    mod_pred = (pd.Series(y_pred) == 3).astype(int)\n",
        "    mod_f1 = f1_score(mod_true, mod_pred, zero_division=0)\n",
        "\n",
        "    # Non-urgent precision (ESI 4&5)\n",
        "    non_true = y_true.isin([4,5]).astype(int)\n",
        "    non_pred = pd.Series(y_pred).isin([4,5]).astype(int)\n",
        "    nprec = precision_score(non_true, non_pred, zero_division=0)\n",
        "\n",
        "    # Over- and Under-triage rates\n",
        "    over = np.sum(pd.Series(y_pred) < y_true)\n",
        "    under = np.sum(pd.Series(y_pred) > y_true)\n",
        "    total = len(y_true)\n",
        "    ot = over / total\n",
        "    ut = under / total\n",
        "\n",
        "    # Error rate\n",
        "    er = 1.0 - acc\n",
        "\n",
        "    return {\n",
        "        'Acc.':     acc,\n",
        "        'P':        p,\n",
        "        'R':        r,\n",
        "        'F1':       f1,\n",
        "        'HR':       hr,\n",
        "        'Mod. F1':  mod_f1,\n",
        "        'NP':       nprec,\n",
        "        'OT':       ot,\n",
        "        'UT':       ut,\n",
        "        'ER':       er\n",
        "    }"
      ],
      "metadata": {
        "id": "m1jVKpuw64N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_emb = embed_texts_fast(df['Serialized'].tolist(), batch_size=64, max_length=64)\n",
        "\n",
        "# 6. Scale embeddings\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_emb)\n",
        "y = df['ESI']\n",
        "\n",
        "# 7. Cross-validated MLP training + predictions\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(512,256),\n",
        "    learning_rate_init=1e-3,\n",
        "    max_iter=100,\n",
        "    early_stopping=True,\n",
        "    random_state=42\n",
        ")\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred = cross_val_predict(mlp, X_scaled, y, cv=cv)\n",
        "y_proba = cross_val_predict(mlp, X_scaled, y, cv=cv, method='predict_proba')\n",
        "\n",
        "\n",
        "\n",
        "metrics_row = compute_metrics_row(pd.Series(np.array(y)), pd.Series(y_pred))\n",
        "df_metrics = pd.DataFrame([metrics_row], index=['ExampleModel'])\n",
        "\n",
        "df_metrics.round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "Y2MW5tER1GjX",
        "outputId": "b29c950a-5ab1-4d3d-ca43-6cf966e5fb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-c57afc3f62b4>:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Acc.     P     R   F1    HR  Mod. F1    NP   OT   UT   ER\n",
              "ExampleModel   0.6  0.56  0.48  0.5  0.59     0.63  0.68  0.2  0.2  0.4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcc0cd09-419b-40ca-b622-d7f6a545e42c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acc.</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F1</th>\n",
              "      <th>HR</th>\n",
              "      <th>Mod. F1</th>\n",
              "      <th>NP</th>\n",
              "      <th>OT</th>\n",
              "      <th>UT</th>\n",
              "      <th>ER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExampleModel</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcc0cd09-419b-40ca-b622-d7f6a545e42c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcc0cd09-419b-40ca-b622-d7f6a545e42c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcc0cd09-419b-40ca-b622-d7f6a545e42c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_metrics\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Acc.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6,\n        \"max\": 0.6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"P\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.56,\n        \"max\": 0.56,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.48,\n        \"max\": 0.48,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.59,\n        \"max\": 0.59,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mod. F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.63,\n        \"max\": 0.63,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.68,\n        \"max\": 0.68,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.2,\n        \"max\": 0.2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.2,\n        \"max\": 0.2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ER\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.4,\n        \"max\": 0.4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fm0P8ikxOgLs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}